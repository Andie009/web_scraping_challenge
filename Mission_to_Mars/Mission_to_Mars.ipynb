{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Splinter, BeautifulSoup, and Pandas\r\n",
    "from splinter import Browser\r\n",
    "import requests\r\n",
    "import pymongo\r\n",
    "from bs4 import BeautifulSoup as soup\r\n",
    "import pandas as pd\r\n",
    "from webdriver_manager.chrome import ChromeDriverManager\r\n",
    "from flask import Flask, render_template, redirect\r\n",
    "from flask_pymongo import PyMongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Splinter\r\n",
    "from webdriver_manager.chrome import ChromeDriverManager\r\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\r\n",
    "browser = Browser('chrome', **executable_path, headless=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visit the NASA mars news site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the Mars News url\r\n",
    "MarsNews_url = \"https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest\"\r\n",
    "browser.visit(MarsNews_url)\r\n",
    "\r\n",
    "# Create HTML object\r\n",
    "html = browser.html\r\n",
    "\r\n",
    "# Parse HTML with BeautifulSoup\r\n",
    "soup = bs(html, 'html.parser')\r\n",
    "\r\n",
    "# Save the news title as variable\r\n",
    "news_title = soup.find('div', class_='content_title').text\r\n",
    "print(news_title)\r\n",
    "\r\n",
    "# Save the paragraph text as variable\r\n",
    "news_p = soup.find('div', class_='article_teaser_body')\r\n",
    "print(news_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JPL Space Images Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use splinter to navigate the site and find the image url for the current Featured Mars Image.\r\n",
    "# Create a browser instance using splinter\r\n",
    "from webdriver_manager.chrome import ChromeDriverManager\r\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\r\n",
    "browser = Browser('chrome', **executable_path, headless=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the Mars News url\r\n",
    "jpl_url = \"https://data-class-jpl-space.s3.amazonaws.com/JPL_Space/index.html\"\r\n",
    "browser.visit(jpl_url)\r\n",
    "\r\n",
    "# Create HTML object\r\n",
    "html = browser.html\r\n",
    "\r\n",
    "# Parse HTML with BeautifulSoup\r\n",
    "soup = bs(html, 'html.parser')\r\n",
    "\r\n",
    "# Save the hero image url as variable\r\n",
    "base_url = 'https://data-class-jpl-space.s3.amazonaws.com/JPL_Space/'\r\n",
    "\r\n",
    "#Find the src of the correct image (hero Image)\r\n",
    "relative_image_path = soup.find_all('img')[1][\"src\"]\r\n",
    "\r\n",
    "# Complete the featured image url by adding the base url ---\r\n",
    "featured_image_url = base_url + relative_image_path\r\n",
    "featured_image_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\r\n",
    "url = 'https://space-facts.com/mars/'\r\n",
    "\r\n",
    "#Use Pandas to convert the data to a HTML table string.\r\n",
    "tables = pd.read_html(url)\r\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the correct DataFrame in the list of DataFrames as assign it to `mars_df`\r\n",
    "mars_df = tables[0]\r\n",
    "mars_df.columns = ['Description', 'Value']\r\n",
    "mars_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find location of all hemisphere titles and thumbnails\r\n",
    "items = soup.find_all('div', class_='item')\r\n",
    "\r\n",
    "#Make empty lists to store the hemisphere name and thumbnail url\r\n",
    "names = []\r\n",
    "urls = []\r\n",
    "\r\n",
    "#Loop through items and store hemisphere name and thumbnail url in lists\r\n",
    "for item in items:\r\n",
    "    urls.append(base_url + item.find('a')['href'])\r\n",
    "    names.append(item.find('h3').text.strip())\r\n",
    "print(names + urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit https://astrogeology.usgs.gov\r\n",
    "url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\r\n",
    "browser.visit(url)\r\n",
    "\r\n",
    "# Scrape page into Soup\r\n",
    "html = browser.html\r\n",
    "soup = bs(html, \"html.parser\")\r\n",
    "\r\n",
    "#Make empty list to store the hemisphere name and image url as dictionaries\r\n",
    "hemisphere_dict_list = []\r\n",
    "\r\n",
    "# Get all elements that contain image information\r\n",
    "items = soup.find_all(\"div\", class_=\"item\")\r\n",
    "\r\n",
    "# Iterate through each image\r\n",
    "for item in items:\r\n",
    "    # Get the Hemisphere name\r\n",
    "    name = item.find(\"h3\").text\r\n",
    "    # Set up to go to hemisphere pages to get full image url\r\n",
    "    end_url = item.find(\"a\")[\"href\"]\r\n",
    "    image_link = \"https://astrogeology.usgs.gov/\" + end_url\r\n",
    "    # Visit Individual hemisphere page   \r\n",
    "    browser.visit(image_link)\r\n",
    "    # Scrape page into Soup\r\n",
    "    html = browser.html\r\n",
    "    soup = bs(html, \"html.parser\")\r\n",
    "    # Get full image url\r\n",
    "    downloads = soup.find(\"div\", class_=\"downloads\")\r\n",
    "    image_url = downloads.find(\"a\")[\"href\"]\r\n",
    "    # Save hemisphere name and image url to empty list as 4 dictionaries\r\n",
    "    hemisphere_dict_list.append({\"Name\": name, \"img_url\": image_url})\r\n",
    "\r\n",
    "# Print image title and url\r\n",
    "print(hemisphere_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary for all info scraped from sources above\r\n",
    "mars_info={\r\n",
    "    \"news_title\":news_title,\r\n",
    "    \"news_p\":news_p,\r\n",
    "    \"featured_image_url\":featured_image_url,\r\n",
    "    \"fact_table\":mars_df,\r\n",
    "    \"hemisphere_images\":hemisphere_dict_list\r\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the browser after scraping\r\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_info"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3437956481a998e42cb24024d7058073f597a4b9fcde3b5ad1badeb773c8ae75"
  },
  "kernel_info": {
   "name": "work"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}